"""
EDU-Audit Multimodal Document Agent
PDF/PPT ë©€í‹°ëª¨ë‹¬ íŒŒì‹± ë° LlamaIndex ì—°ë™ - í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼
"""

import asyncio
import logging
import os
import base64
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from io import BytesIO

# PDF/PPT íŒŒì‹± ë¼ì´ë¸ŒëŸ¬ë¦¬
import pdfplumber
from pptx import Presentation
from PIL import Image
import fitz  # PyMuPDF for image extraction

# OCR ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import easyocr
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False
    logging.warning("EasyOCR not available. Install with: pip install easyocr")

# LlamaIndex ê´€ë ¨
from llama_index.core import Document, VectorStoreIndex
from llama_index.core.node_parser import SentenceSplitter
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI

# í™•ì¥ëœ ëª¨ë¸ë“¤
from src.core.models import (
    DocumentMeta, PageInfo, PageElement, ElementType,
    ImageElement, TableElement, ChartElement, BoundingBox,
    generate_doc_id, generate_element_id
)
from dotenv import load_dotenv

env_path = Path(__file__).resolve().parents[2] / '.env.dev'
load_dotenv(env_path)

logger = logging.getLogger(__name__)

class MultimodalDocumentAgent:
    """ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ íŒŒì‹± ë° LlamaIndex ê´€ë¦¬ ì—ì´ì „íŠ¸"""
    
    def __init__(
        self, 
        openai_api_key: Optional[str] = None,
        vision_model: str = "gpt-4-vision-preview",
        chunk_size: int = 512,
        chunk_overlap: int = 50,
        enable_ocr: bool = True,
        enable_vision_analysis: bool = True
    ):
        self.openai_api_key = openai_api_key
        self.vision_model = vision_model
        self.enable_ocr = enable_ocr and OCR_AVAILABLE
        self.enable_vision_analysis = enable_vision_analysis and openai_api_key
        
        # LlamaIndex ì»´í¬ë„ŒíŠ¸
        self.embeddings = OpenAIEmbedding(api_key=openai_api_key)
        self.text_splitter = SentenceSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
        
        # Vision LLM (ì´ë¯¸ì§€ ë¶„ì„ìš©)
        self.vision_llm = None
        if self.enable_vision_analysis:
            self.vision_llm = OpenAI(
                model=vision_model,
                api_key=openai_api_key,
                temperature=0.1
            )
        
        # OCR ì´ˆê¸°í™”
        self.ocr_reader = None
        if self.enable_ocr:
            try:
                self.ocr_reader = easyocr.Reader(['ko', 'en'])
                logger.info("EasyOCR ì´ˆê¸°í™” ì™„ë£Œ (í•œêµ­ì–´, ì˜ì–´)")
            except Exception as e:
                logger.warning(f"OCR ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                self.enable_ocr = False
        
        # ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ë¬¸ì„œë“¤
        self.documents: Dict[str, DocumentMeta] = {}
        self.pages: Dict[str, List[PageInfo]] = {}  # doc_id -> pages
        self.indexes: Dict[str, VectorStoreIndex] = {}  # doc_id -> index
        
        logger.info(f"MultimodalDocumentAgent ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"  OCR: {'í™œì„±í™”' if self.enable_ocr else 'ë¹„í™œì„±í™”'}")
        logger.info(f"  Vision ë¶„ì„: {'í™œì„±í™”' if self.enable_vision_analysis else 'ë¹„í™œì„±í™”'}")
    
    async def parse_document(self, file_path: str) -> DocumentMeta:
        """
        ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ íŒŒì‹± ë° LlamaIndex ì¸ë±ì‹±
        
        Args:
            file_path: íŒŒì‹±í•  ë¬¸ì„œ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            DocumentMeta: íŒŒì‹±ëœ ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
        """
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        logger.info(f"ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ íŒŒì‹± ì‹œì‘: {file_path}")
        
        # ë¬¸ì„œ ID ìƒì„±
        doc_id = generate_doc_id(str(file_path))
        
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ íŒŒì‹±
        if file_path.suffix.lower() == '.pdf':
            doc_meta, pages = await self._parse_pdf_multimodal(file_path, doc_id)
        elif file_path.suffix.lower() in ['.ppt', '.pptx']:
            doc_meta, pages = await self._parse_ppt_multimodal(file_path, doc_id)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_path.suffix}")
        
        # ë©€í‹°ëª¨ë‹¬ í†µê³„ ì—…ë°ì´íŠ¸
        doc_meta.total_images = sum(page.image_count for page in pages)
        doc_meta.total_tables = sum(page.table_count for page in pages)
        doc_meta.total_charts = sum(page.chart_count for page in pages)
        
        # ë©”ëª¨ë¦¬ì— ì €ì¥
        self.documents[doc_id] = doc_meta
        self.pages[doc_id] = pages
        
        # ë©€í‹°ëª¨ë‹¬ LlamaIndex ì¸ë±ìŠ¤ ìƒì„±
        await self._create_multimodal_index(doc_id, pages)
        
        logger.info(f"ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ íŒŒì‹± ì™„ë£Œ: {doc_id}")
        logger.info(f"  ì´ {len(pages)} í˜ì´ì§€, {doc_meta.total_images} ì´ë¯¸ì§€, {doc_meta.total_tables} í‘œ, {doc_meta.total_charts} ì°¨íŠ¸")
        return doc_meta
    
    async def _parse_pdf_multimodal(self, file_path: Path, doc_id: str) -> Tuple[DocumentMeta, List[PageInfo]]:
        """PDF ë©€í‹°ëª¨ë‹¬ íŒŒì‹±"""
        logger.info(f"PDF ë©€í‹°ëª¨ë‹¬ íŒŒì‹± ì¤‘: {file_path}")
        
        pages = []
        title = None
        
        try:
            # PyMuPDFë¡œ ì´ë¯¸ì§€ ì¶”ì¶œìš©
            pdf_doc = fitz.open(file_path)
            
            with pdfplumber.open(file_path) as pdf:
                # ì²« í˜ì´ì§€ì—ì„œ ì œëª© ì¶”ì¶œ
                if pdf.pages:
                    first_page_text = pdf.pages[0].extract_text() or ""
                    title = self._extract_title_from_text(first_page_text)
                
                # ê° í˜ì´ì§€ íŒŒì‹±
                for page_num, page in enumerate(pdf.pages, 1):
                    logger.info(f"í˜ì´ì§€ {page_num} íŒŒì‹± ì¤‘...")
                    
                    # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    page_text = page.extract_text() or ""
                    
                    # ë©€í‹°ëª¨ë‹¬ ìš”ì†Œë“¤ ì¶”ì¶œ
                    elements = []
                    
                    # 1. í…ìŠ¤íŠ¸ ìš”ì†Œ ì¶”ê°€
                    if page_text.strip():
                        text_element = PageElement(
                            element_id=generate_element_id(f"p{page_num:03d}", ElementType.TEXT, 0),
                            element_type=ElementType.TEXT,
                            text_content=page_text,
                            confidence=1.0
                        )
                        elements.append(text_element)
                    
                    # 2. ì´ë¯¸ì§€ ì¶”ì¶œ ë° ë¶„ì„
                    fitz_page = pdf_doc[page_num - 1]
                    image_elements = await self._extract_images_from_page(
                        page, fitz_page, f"p{page_num:03d}"
                    )
                    elements.extend(image_elements)
                    
                    # 3. í‘œ ì¶”ì¶œ
                    table_elements = await self._extract_tables_from_page(
                        page, f"p{page_num:03d}"
                    )
                    elements.extend(table_elements)
                    
                    # 4. ì°¨íŠ¸ ê°ì§€ (ì´ë¯¸ì§€ ê¸°ë°˜)
                    chart_elements = await self._detect_charts_in_images(
                        image_elements, f"p{page_num:03d}"
                    )
                    elements.extend(chart_elements)
                    
                    # PageInfo ìƒì„±
                    page_info = PageInfo(
                        page_id=f"p{page_num:03d}",
                        page_number=page_num,
                        raw_text=page_text,
                        word_count=len(page_text.split()) if page_text else 0,
                        elements=elements
                    )
                    
                    pages.append(page_info)
                    
                    # ì§„í–‰ìƒí™© ë¡œê·¸
                    if page_num % 5 == 0:
                        logger.info(f"PDF íŒŒì‹± ì§„í–‰: {page_num}/{len(pdf.pages)} í˜ì´ì§€")
        
        except Exception as e:
            logger.error(f"PDF íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            raise
        finally:
            if 'pdf_doc' in locals():
                pdf_doc.close()
        
        # ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ìƒì„±
        doc_meta = DocumentMeta(
            doc_id=doc_id,
            title=title or file_path.stem,
            doc_type="pdf",
            total_pages=len(pages),
            file_path=str(file_path)
        )
        
        return doc_meta, pages
    
    async def _parse_ppt_multimodal(self, file_path: Path, doc_id: str) -> Tuple[DocumentMeta, List[PageInfo]]:
        """PowerPoint ë©€í‹°ëª¨ë‹¬ íŒŒì‹±"""
        logger.info(f"PPT ë©€í‹°ëª¨ë‹¬ íŒŒì‹± ì¤‘: {file_path}")
        
        pages = []
        title = None
        
        try:
            prs = Presentation(file_path)
            
            # ì²« ìŠ¬ë¼ì´ë“œì—ì„œ ì œëª© ì¶”ì¶œ
            if prs.slides:
                first_slide_text = self._extract_slide_text(prs.slides[0])
                title = self._extract_title_from_text(first_slide_text)
            
            # ê° ìŠ¬ë¼ì´ë“œ íŒŒì‹±
            for slide_num, slide in enumerate(prs.slides, 1):
                logger.info(f"ìŠ¬ë¼ì´ë“œ {slide_num} íŒŒì‹± ì¤‘...")
                
                elements = []
                slide_text_parts = []
                
                # ìŠ¬ë¼ì´ë“œ ë‚´ ëª¨ë“  shape ë¶„ì„
                element_index = 0
                
                for shape in slide.shapes:
                    if hasattr(shape, "text") and shape.text.strip():
                        # í…ìŠ¤íŠ¸ ìš”ì†Œ
                        text_element = PageElement(
                            element_id=generate_element_id(f"slide_{slide_num:03d}", ElementType.TEXT, element_index),
                            element_type=ElementType.TEXT,
                            bbox=self._shape_to_bbox(shape),
                            text_content=shape.text.strip(),
                            confidence=1.0
                        )
                        elements.append(text_element)
                        slide_text_parts.append(shape.text.strip())
                        element_index += 1
                    
                    elif shape.shape_type == 13: # msoPicture
                        # ì´ë¯¸ì§€ ìš”ì†Œ
                        image_element = await self._extract_ppt_image(
                            shape, f"slide_{slide_num:03d}", element_index
                        )
                        if image_element:
                            elements.append(image_element)
                            element_index += 1
                    
                    elif shape.has_table:
                        # í‘œ ìš”ì†Œ
                        table_element = await self._extract_ppt_table(
                            shape.table, f"slide_{slide_num:03d}", element_index
                        )
                        if table_element:
                            elements.append(table_element)
                            element_index += 1
                
                # ì „ì²´ ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸
                slide_text = "\n".join(slide_text_parts)
                
                # PageInfo ìƒì„±
                page_info = PageInfo(
                    page_id=f"slide_{slide_num:03d}",
                    page_number=slide_num,
                    raw_text=slide_text,
                    word_count=len(slide_text.split()) if slide_text else 0,
                    elements=elements
                )
                
                pages.append(page_info)
        
        except Exception as e:
            logger.error(f"PPT íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            raise
        
        # ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ìƒì„±
        doc_meta = DocumentMeta(
            doc_id=doc_id,
            title=title or file_path.stem,
            doc_type="ppt",
            total_pages=len(pages),
            file_path=str(file_path)
        )
        
        return doc_meta, pages
    
    async def _extract_images_from_page(self, pdfplumber_page, fitz_page, page_id: str) -> List[PageElement]:
        """PDF í˜ì´ì§€ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ ë° ë¶„ì„"""
        elements = []
        
        try:
            # PyMuPDFë¡œ ì´ë¯¸ì§€ ì¶”ì¶œ
            image_list = fitz_page.get_images()
            
            for img_index, img in enumerate(image_list):
                try:
                    # ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
                    xref = img[0]
                    pix = fitz.Pixmap(fitz_page.parent, xref)
                    
                    if pix.n - pix.alpha < 4:  # GRAY or RGB
                        img_data = pix.pil_tobytes(format="PNG")
                        pil_image = Image.open(BytesIO(img_data))
                        
                        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
                        buffered = BytesIO()
                        pil_image.save(buffered, format="PNG")
                        img_base64 = base64.b64encode(buffered.getvalue()).decode()
                        
                        # ì´ë¯¸ì§€ ë¶„ì„
                        image_analysis = await self._analyze_image(pil_image, img_base64)
                        
                        # ì´ë¯¸ì§€ ìš”ì†Œ ìƒì„±
                        image_element = PageElement(
                            element_id=generate_element_id(page_id, ElementType.IMAGE, img_index),
                            element_type=ElementType.IMAGE,
                            bbox=BoundingBox(x=0, y=0, width=pil_image.width, height=pil_image.height),
                            image_data=ImageElement(
                                element_id=generate_element_id(page_id, ElementType.IMAGE, img_index),
                                bbox=BoundingBox(x=0, y=0, width=pil_image.width, height=pil_image.height),
                                format="png",
                                size_bytes=len(img_data),
                                dimensions=(pil_image.width, pil_image.height),
                                ocr_text=image_analysis.get("ocr_text"),
                                description=image_analysis.get("description"),
                                image_data=f"data:image/png;base64,{img_base64}"
                            ),
                            confidence=image_analysis.get("confidence", 0.8)
                        )
                        
                        elements.append(image_element)
                        
                    pix = None  # ë©”ëª¨ë¦¬ í•´ì œ
                    
                except Exception as e:
                    logger.warning(f"ì´ë¯¸ì§€ {img_index} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        
        except Exception as e:
            logger.warning(f"í˜ì´ì§€ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        
        return elements
    
    async def _analyze_image(self, pil_image: Image.Image, img_base64: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ë¶„ì„ (OCR + Vision LLM)"""
        analysis = {
            "ocr_text": None,
            "description": None,
            "confidence": 0.5
        }
        
        # 1. OCR ë¶„ì„
        if self.enable_ocr and self.ocr_reader:
            try:
                # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
                import numpy as np
                img_array = np.array(pil_image)
                
                ocr_results = self.ocr_reader.readtext(img_array)
                if ocr_results:
                    ocr_texts = [result[1] for result in ocr_results if result[2] > 0.5]
                    analysis["ocr_text"] = " ".join(ocr_texts)
                    analysis["confidence"] = max(analysis["confidence"], 0.7)
                
            except Exception as e:
                logger.warning(f"OCR ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        # 2. Vision LLM ë¶„ì„
        if self.enable_vision_analysis and self.vision_llm:
            try:
                description = await self._get_image_description(img_base64)
                if description:
                    analysis["description"] = description
                    analysis["confidence"] = max(analysis["confidence"], 0.8)
                
            except Exception as e:
                logger.warning(f"Vision LLM ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        return analysis
    
    async def _get_image_description(self, img_base64: str) -> Optional[str]:
        """Vision LLMìœ¼ë¡œ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±"""
        if not self.vision_llm:
            return None
        
        try:
            prompt = """ì´ ì´ë¯¸ì§€ë¥¼ êµìœ¡ ì½˜í…ì¸  ê²€ìˆ˜ ê´€ì ì—ì„œ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
            
ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
- ì´ë¯¸ì§€ íƒ€ì… (ë‹¤ì´ì–´ê·¸ë¨, ì°¨íŠ¸, ì‚¬ì§„, ìŠ¤í¬ë¦°ìƒ· ë“±)
- ì£¼ìš” ë‚´ìš© (í•œ ì¤„ ìš”ì•½)
- í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ ì£¼ìš” ë‚´ìš©
- êµìœ¡ì  ëª©ì  (ì„¤ëª…, ì˜ˆì‹œ, ë°ì´í„° ë“±)

ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""
            
            # OpenAI Vision APIëŠ” ë³„ë„ êµ¬í˜„ í•„ìš”
            # í˜„ì¬ëŠ” í”Œë ˆì´ìŠ¤í™€ë”
            response = await self._call_vision_api(prompt, img_base64)
            return response
            
        except Exception as e:
            logger.warning(f"ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return None
    
    async def _call_vision_api(self, prompt: str, img_base64: str) -> Optional[str]:
        """Vision API í˜¸ì¶œ (OpenAI GPT-4V)"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” OpenAIì˜ vision APIë¥¼ í˜¸ì¶œ
        # í˜„ì¬ëŠ” ë”ë¯¸ ì‘ë‹µ
        await asyncio.sleep(0.1)  # API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        return "ë‹¤ì´ì–´ê·¸ë¨: ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ë³´ì—¬ì£¼ëŠ” êµìœ¡ìš© ì´ë¯¸ì§€"
    
    async def _extract_tables_from_page(self, page, page_id: str) -> List[PageElement]:
        """PDF í˜ì´ì§€ì—ì„œ í‘œ ì¶”ì¶œ"""
        elements = []
        
        try:
            tables = page.extract_tables()
            
            for table_index, table_data in enumerate(tables):
                if not table_data or len(table_data) < 2:
                    continue
                
                # í—¤ë”ì™€ ë°ì´í„° ë¶„ë¦¬
                headers = table_data[0] if table_data else []
                rows = table_data[1:] if len(table_data) > 1 else []
                
                # None ê°’ ì •ë¦¬
                headers = [str(cell) if cell is not None else "" for cell in headers]
                clean_rows = []
                for row in rows:
                    clean_row = [str(cell) if cell is not None else "" for cell in row]
                    clean_rows.append(clean_row)
                
                table_element = PageElement(
                    element_id=generate_element_id(page_id, ElementType.TABLE, table_index),
                    element_type=ElementType.TABLE,
                    table_data=TableElement(
                        element_id=generate_element_id(page_id, ElementType.TABLE, table_index),
                        headers=headers,
                        rows=clean_rows,
                        extraction_confidence=0.9
                    ),
                    confidence=0.9
                )
                
                elements.append(table_element)
        
        except Exception as e:
            logger.warning(f"í‘œ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        
        return elements
    
    async def _detect_charts_in_images(self, image_elements: List[PageElement], page_id: str) -> List[PageElement]:
        """ì´ë¯¸ì§€ì—ì„œ ì°¨íŠ¸ ê°ì§€"""
        chart_elements = []
        
        for img_element in image_elements:
            if not img_element.image_data or not img_element.image_data.description:
                continue
            
            description = img_element.image_data.description.lower()
            
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì°¨íŠ¸ ê°ì§€
            chart_keywords = ["ì°¨íŠ¸", "ê·¸ë˜í”„", "ë„í‘œ", "chart", "graph", "plot"]
            
            if any(keyword in description for keyword in chart_keywords):
                # ì°¨íŠ¸ ìš”ì†Œë¡œ ë³€í™˜
                chart_element = PageElement(
                    element_id=img_element.element_id.replace("image", "chart"),
                    element_type=ElementType.CHART,
                    bbox=img_element.bbox,
                    chart_data=ChartElement(
                        element_id=img_element.element_id.replace("image", "chart"),
                        bbox=img_element.bbox,
                        chart_type="unknown",
                        description=img_element.image_data.description
                    ),
                    confidence=0.7
                )
                
                chart_elements.append(chart_element)
        
        return chart_elements
    
    async def _extract_ppt_image(self, shape, page_id: str, element_index: int) -> Optional[PageElement]:
        """PPTì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        try:
            # PPT ì´ë¯¸ì§€ ì²˜ë¦¬ëŠ” ë³µì¡í•˜ë¯€ë¡œ ê¸°ë³¸ êµ¬í˜„ë§Œ
            image_element = PageElement(
                element_id=generate_element_id(page_id, ElementType.IMAGE, element_index),
                element_type=ElementType.IMAGE,
                bbox=self._shape_to_bbox(shape),
                image_data=ImageElement(
                    element_id=generate_element_id(page_id, ElementType.IMAGE, element_index),
                    bbox=self._shape_to_bbox(shape),
                    format="unknown",
                    size_bytes=0,
                    dimensions=(100, 100),
                    description="PPT ì´ë¯¸ì§€"
                ),
                confidence=0.6
            )
            
            return image_element
            
        except Exception as e:
            logger.warning(f"PPT ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    async def _extract_ppt_table(self, table, page_id: str, element_index: int) -> Optional[PageElement]:
        """PPTì—ì„œ í‘œ ì¶”ì¶œ"""
        try:
            headers, rows = [], []

            # ğŸ‘‡ ìŠ¬ë¼ì´ì‹±(table.rows[1:]) ì ˆëŒ€ ì“°ì§€ ë§ˆì„¸ìš”.
            row_list = list(table.rows)  # ì•ˆì „í•˜ê²Œ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³µì œ

            if len(row_list) == 0:
                return None

            # ì²« í–‰ì„ í—¤ë”ë¡œ
            first_row = row_list[0]
            headers = [cell.text.strip() for cell in first_row.cells]

            # ë‚˜ë¨¸ì§€ëŠ” ë°ì´í„°
            for r in row_list[1:]:
                rows.append([cell.text.strip() for cell in r.cells])

            table_element = PageElement(
                element_id=generate_element_id(page_id, ElementType.TABLE, element_index),
                element_type=ElementType.TABLE,
                table_data=TableElement(
                    element_id=generate_element_id(page_id, ElementType.TABLE, element_index),
                    headers=headers,
                    rows=rows,
                    extraction_confidence=0.8
                ),
                confidence=0.8
            )
            return table_element

        except Exception as e:
            logger.warning(f"PPT í‘œ ì¶”ì¶œ ì‹¤íŒ¨: {e!r}")  # reprë¡œ ì—ëŸ¬ ì›ì¸ ë” ëª…í™•íˆ
            return None
    
    def _emu_to_px(self, emu_val: Any, dpi: int = 96) -> int:
        # 1 inch = 914400 EMU, 96 px/inch
        try:
            emu = int(emu_val)
        except Exception:
            emu = int(float(emu_val))
        px = int(round(emu * dpi / 914400))
        return max(0, px)  # ìŒìˆ˜ ë°©ì§€

    def _shape_to_bbox(self, shape) -> BoundingBox:
        x = self._emu_to_px(shape.left)
        y = self._emu_to_px(shape.top)
        w = max(1, self._emu_to_px(shape.width))   # 0 ë°©ì§€
        h = max(1, self._emu_to_px(shape.height))  # 0 ë°©ì§€
        return BoundingBox(x=x, y=y, width=w, height=h)
    
    def _extract_slide_text(self, slide) -> str:
        """ìŠ¬ë¼ì´ë“œì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        texts = []
        
        for shape in slide.shapes:
            if hasattr(shape, "text") and shape.text:
                texts.append(shape.text.strip())
        
        return "\n".join(texts)
    
    def _extract_title_from_text(self, text: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì œëª© ì¶”ì¶œ"""
        if not text:
            return None
        
        lines = text.strip().split('\n')
        first_line = lines[0].strip()
        
        if 5 <= len(first_line) <= 100:
            return first_line
        
        return None
    
    async def _create_multimodal_index(self, doc_id: str, pages: List[PageInfo]):
        """ë©€í‹°ëª¨ë‹¬ ìš”ì†Œë¥¼ í¬í•¨í•œ LlamaIndex ìƒì„±"""
        logger.info(f"ë©€í‹°ëª¨ë‹¬ ì¸ë±ìŠ¤ ìƒì„± ì¤‘: {doc_id}")
        
        documents = []
        
        for page in pages:
            # ê° ìš”ì†Œë¥¼ ë³„ë„ ë¬¸ì„œë¡œ ì¸ë±ì‹±
            for element in page.elements:
                text_content = ""
                
                if element.element_type == ElementType.TEXT:
                    text_content = element.text_content or ""
                
                elif element.element_type == ElementType.IMAGE:
                    # ì´ë¯¸ì§€ì˜ OCR í…ìŠ¤íŠ¸ì™€ ì„¤ëª… ê²°í•©
                    parts = []
                    if element.image_data and element.image_data.ocr_text:
                        parts.append(f"[OCR] {element.image_data.ocr_text}")
                    if element.image_data and element.image_data.description:
                        parts.append(f"[ì„¤ëª…] {element.image_data.description}")
                    text_content = " ".join(parts)
                
                elif element.element_type == ElementType.TABLE:
                    # í‘œ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    if element.table_data:
                        parts = []
                        if element.table_data.headers:
                            parts.append(f"[í—¤ë”] {' | '.join(element.table_data.headers)}")
                        for row in element.table_data.rows:
                            parts.append(f"[í–‰] {' | '.join(row)}")
                        text_content = "\n".join(parts)
                
                elif element.element_type == ElementType.CHART:
                    # ì°¨íŠ¸ ì„¤ëª…
                    if element.chart_data and element.chart_data.description:
                        text_content = f"[ì°¨íŠ¸] {element.chart_data.description}"
                
                if text_content.strip():
                    doc = Document(
                        text=text_content,
                        metadata={
                            "doc_id": doc_id,
                            "page_id": page.page_id,
                            "page_number": page.page_number,
                            "element_id": element.element_id,
                            "element_type": element.element_type.value,
                            "confidence": element.confidence
                        }
                    )
                    documents.append(doc)
        
        if not documents:
            logger.warning(f"ì¸ë±ì‹±í•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤: {doc_id}")
            return
        
        try:
            # ë©€í‹°ëª¨ë‹¬ ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±
            index = VectorStoreIndex.from_documents(
                documents,
                embed_model=self.embeddings,
                transformations=[self.text_splitter]
            )
            
            self.indexes[doc_id] = index
            logger.info(f"ë©€í‹°ëª¨ë‹¬ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {doc_id} ({len(documents)} ìš”ì†Œ)")
            
        except Exception as e:
            logger.error(f"ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    # ê¸°ì¡´ DocumentAgentì˜ ë©”ì„œë“œë“¤ ìœ ì§€
    def get_document(self, doc_id: str) -> Optional[DocumentMeta]:
        """ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
        return self.documents.get(doc_id)
    
    def get_pages(self, doc_id: str) -> List[PageInfo]:
        """ë¬¸ì„œì˜ í˜ì´ì§€ ëª©ë¡ ì¡°íšŒ"""
        return self.pages.get(doc_id, [])
    
    def get_index(self, doc_id: str) -> Optional[VectorStoreIndex]:
        """ë¬¸ì„œì˜ ë²¡í„° ì¸ë±ìŠ¤ ì¡°íšŒ"""
        return self.indexes.get(doc_id)
    
    def search_in_document(self, doc_id: str, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ë‚´ ê²€ìƒ‰"""
        index = self.get_index(doc_id)
        if not index:
            return []
        
        try:
            # ì¿¼ë¦¬ ì—”ì§„ ìƒì„±
            query_engine = index.as_query_engine(similarity_top_k=top_k)
            
            # ê²€ìƒ‰ ìˆ˜í–‰
            response = query_engine.query(query)
            
            # ê²°ê³¼ ì •ë¦¬
            results = []
            for node in response.source_nodes:
                results.append({
                    "text": node.text,
                    "score": node.score,
                    "metadata": node.metadata,
                    "page_id": node.metadata.get("page_id"),
                    "page_number": node.metadata.get("page_number"),
                    "element_id": node.metadata.get("element_id"),
                    "element_type": node.metadata.get("element_type"),
                    "confidence": node.metadata.get("confidence")
                })
            
            return results
            
        except Exception as e:
            logger.error(f"ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def search_by_element_type(self, doc_id: str, element_type: ElementType, query: str = None) -> List[PageElement]:
        """ìš”ì†Œ íƒ€ì…ë³„ ê²€ìƒ‰"""
        pages = self.get_pages(doc_id)
        if not pages:
            return []
        
        results = []
        for page in pages:
            for element in page.elements:
                if element.element_type == element_type:
                    # ì¿¼ë¦¬ê°€ ìˆëŠ” ê²½ìš° í…ìŠ¤íŠ¸ ë§¤ì¹­
                    if query:
                        element_text = ""
                        if element.element_type == ElementType.TEXT:
                            element_text = element.text_content or ""
                        elif element.element_type == ElementType.IMAGE and element.image_data:
                            element_text = f"{element.image_data.ocr_text or ''} {element.image_data.description or ''}"
                        elif element.element_type == ElementType.TABLE and element.table_data:
                            element_text = f"{' '.join(element.table_data.headers)} {' '.join([' '.join(row) for row in element.table_data.rows])}"
                        elif element.element_type == ElementType.CHART and element.chart_data:
                            element_text = element.chart_data.description or ""
                        
                        if query.lower() in element_text.lower():
                            results.append(element)
                    else:
                        results.append(element)
        
        return results
    
    def get_multimodal_stats(self, doc_id: str) -> Dict[str, Any]:
        """ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ í†µê³„"""
        doc_meta = self.get_document(doc_id)
        pages = self.get_pages(doc_id)
        
        if not doc_meta or not pages:
            return {}
        
        # ìš”ì†Œë³„ í†µê³„ ê³„ì‚°
        element_stats = {
            "text": 0,
            "image": 0,
            "table": 0,
            "chart": 0,
            "total": 0
        }
        
        total_words = 0
        total_chars = 0
        ocr_text_count = 0
        ai_descriptions = 0
        
        for page in pages:
            total_words += page.word_count
            total_chars += len(page.raw_text)
            
            for element in page.elements:
                element_stats["total"] += 1
                
                if element.element_type == ElementType.TEXT:
                    element_stats["text"] += 1
                elif element.element_type == ElementType.IMAGE:
                    element_stats["image"] += 1
                    if element.image_data:
                        if element.image_data.ocr_text:
                            ocr_text_count += 1
                        if element.image_data.description:
                            ai_descriptions += 1
                elif element.element_type == ElementType.TABLE:
                    element_stats["table"] += 1
                elif element.element_type == ElementType.CHART:
                    element_stats["chart"] += 1
        
        return {
            "doc_id": doc_id,
            "title": doc_meta.title,
            "total_pages": len(pages),
            "total_words": total_words,
            "total_chars": total_chars,
            "avg_words_per_page": total_words / len(pages) if pages else 0,
            "has_index": doc_id in self.indexes,
            "elements": element_stats,
            "multimodal_features": {
                "ocr_enabled": self.enable_ocr,
                "vision_analysis_enabled": self.enable_vision_analysis,
                "ocr_text_extracted": ocr_text_count,
                "ai_descriptions_generated": ai_descriptions
            }
        }
    
    def list_documents(self) -> List[DocumentMeta]:
        """ëª¨ë“  ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ"""
        return list(self.documents.values())
    
    async def get_page_summary(self, doc_id: str, page_id: str) -> Dict[str, Any]:
        """í˜ì´ì§€ ìš”ì•½ ì •ë³´"""
        pages = self.get_pages(doc_id)
        target_page = None
        
        for page in pages:
            if page.page_id == page_id:
                target_page = page
                break
        
        if not target_page:
            return {}
        
        # ìš”ì†Œë³„ ìš”ì•½
        summary = {
            "page_id": page_id,
            "page_number": target_page.page_number,
            "word_count": target_page.word_count,
            "element_counts": {
                "text": target_page.text_count,
                "image": target_page.image_count,
                "table": target_page.table_count,
                "chart": target_page.chart_count
            },
            "elements": []
        }
        
        # ê° ìš”ì†Œì˜ ìš”ì•½ ì •ë³´
        for element in target_page.elements:
            element_summary = {
                "element_id": element.element_id,
                "element_type": element.element_type.value,
                "confidence": element.confidence
            }
            
            if element.element_type == ElementType.TEXT:
                element_summary["preview"] = (element.text_content or "")[:100]
            elif element.element_type == ElementType.IMAGE and element.image_data:
                element_summary["description"] = element.image_data.description
                element_summary["has_ocr"] = bool(element.image_data.ocr_text)
            elif element.element_type == ElementType.TABLE and element.table_data:
                element_summary["dimensions"] = f"{element.table_data.row_count}x{element.table_data.col_count}"
                element_summary["has_headers"] = element.table_data.has_headers
            elif element.element_type == ElementType.CHART and element.chart_data:
                element_summary["chart_type"] = element.chart_data.chart_type
                element_summary["description"] = element.chart_data.description
            
            summary["elements"].append(element_summary)
        
        return summary


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_multimodal_agent():
    """MultimodalDocumentAgent í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª MultimodalDocumentAgent í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ì—ì´ì „íŠ¸ ìƒì„±
    import os
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        print("âš ï¸  OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ë©€í‹°ëª¨ë‹¬ ê¸°ëŠ¥ ì¼ë¶€ê°€ ì œí•œë©ë‹ˆë‹¤.")
    
    agent = MultimodalDocumentAgent(
        openai_api_key=api_key,
        enable_ocr=True,
        enable_vision_analysis=bool(api_key)
    )
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤
    test_files = [
        "Ch01_intro.pdf",
        "Ch01_intro.pptx"
    ]
    
    for test_file in test_files:
        if Path(test_file).exists():
            try:
                print(f"\nğŸ“„ ë©€í‹°ëª¨ë‹¬ íŒŒì‹± í…ŒìŠ¤íŠ¸: {test_file}")
                
                # ë¬¸ì„œ íŒŒì‹±
                doc_meta = await agent.parse_document(test_file)
                
                print(f"âœ… íŒŒì‹± ì„±ê³µ!")
                print(f"   ë¬¸ì„œ ID: {doc_meta.doc_id}")
                print(f"   ì œëª©: {doc_meta.title}")
                print(f"   í˜ì´ì§€ ìˆ˜: {doc_meta.total_pages}")
                print(f"   ì´ë¯¸ì§€: {doc_meta.total_images}ê°œ")
                print(f"   í‘œ: {doc_meta.total_tables}ê°œ")
                print(f"   ì°¨íŠ¸: {doc_meta.total_charts}ê°œ")
                
                # ë©€í‹°ëª¨ë‹¬ í†µê³„
                stats = agent.get_multimodal_stats(doc_meta.doc_id)
                print(f"   ì´ ìš”ì†Œ: {stats['elements']['total']}ê°œ")
                print(f"   OCR ì¶”ì¶œ: {stats['multimodal_features']['ocr_text_extracted']}ê°œ")
                print(f"   AI ì„¤ëª…: {stats['multimodal_features']['ai_descriptions_generated']}ê°œ")
                
                # ìš”ì†Œ íƒ€ì…ë³„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
                images = agent.search_by_element_type(doc_meta.doc_id, ElementType.IMAGE)
                tables = agent.search_by_element_type(doc_meta.doc_id, ElementType.TABLE)
                print(f"   ì´ë¯¸ì§€ ê²€ìƒ‰: {len(images)}ê°œ ë°œê²¬")
                print(f"   í‘œ ê²€ìƒ‰: {len(tables)}ê°œ ë°œê²¬")
                
                # ì²« ë²ˆì§¸ í˜ì´ì§€ ìš”ì•½
                if stats['total_pages'] > 0:
                    pages = agent.get_pages(doc_meta.doc_id)
                    if pages:
                        page_summary = await agent.get_page_summary(doc_meta.doc_id, pages[0].page_id)
                        print(f"   ì²« í˜ì´ì§€ ìš”ì†Œ: {len(page_summary.get('elements', []))}ê°œ")
                
                # ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
                if api_key and stats.get('has_index'):
                    search_results = agent.search_in_document(
                        doc_meta.doc_id,
                        "ì´ë¯¸ì§€",
                        top_k=3
                    )
                    print(f"   ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ")
                    
                    for result in search_results[:2]:  # ì²˜ìŒ 2ê°œë§Œ ì¶œë ¥
                        print(f"     - {result['element_type']}: {result['text'][:50]}...")
                
            except Exception as e:
                print(f"âŒ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                import traceback
                traceback.print_exc()
        else:
            print(f"â­ï¸  í…ŒìŠ¤íŠ¸ íŒŒì¼ ì—†ìŒ: {test_file}")
    
    # ë¬¸ì„œ ëª©ë¡ ì¶œë ¥
    docs = agent.list_documents()
    print(f"\nğŸ“š ì´ {len(docs)}ê°œ ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ë¡œë“œë¨")
    
    print("ğŸ‰ MultimodalDocumentAgent í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(test_multimodal_agent())