"""
EDU-Audit Core Models
í•µì‹¬ ë°ì´í„° êµ¬ì¡° ì •ì˜ - MCP ë„êµ¬ ì¸í„°í˜ì´ìŠ¤ì— ë§ì¶˜ ì„¤ê³„
"""

from datetime import datetime
from enum import Enum
from typing import List, Optional, Dict, Any, Union
from pydantic import BaseModel, Field, field_validator, model_validator, ValidationInfo
import json

class IssueType(str, Enum):
    """ë°œê²¬ ê°€ëŠ¥í•œ ì´ìŠˆ ìš”í˜•"""
    TYPO = "typo"
    CONSISTENCY = "consistency"
    FACT = "fact"
    GRAMMAR = "grammar"

class ConfidenceLevel(str, Enum):
    """ì‹ ë¢°ë„ ìˆ˜ì¤€"""
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"

class TextLocation(BaseModel):
    """í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì •ë³´"""
    start: int = Field(..., ge=0, description="ì‹œì‘ ìœ„ì¹˜")
    end: int = Field(..., ge=0, description="ì¢…ë£Œ ìœ„ì¹˜")

    @field_validator('end')
    def end_after_start(cls, v, info: ValidationInfo):
        if (start := info.data.get('start')) is not None and v <= start:
            raise ValueError('end must be greater than start')
        return v

class PageInfo(BaseModel):
    """í˜ì´ì§€ ì •ë³´"""
    page_id: str = Field(..., description="í˜ì´ì§€ ID (ì˜ˆ: p001, slide_03)")
    page_number: int = Field(..., ge=1, description="í˜ì´ì§€ ë²ˆí˜¸")
    raw_text: str = Field(default="", description="ì›ë³¸ í…ìŠ¤íŠ¸")
    word_count: int = Field(default=0, ge=0, description="ë‹¨ì–´ ìˆ˜")


class DocumentMeta(BaseModel):
    """ë¬¸ì„œ ë©”íƒ€ë°ì´í„°"""
    doc_id: str = Field(..., description="ë¬¸ì„œ ê³ ìœ  ID")
    title: Optional[str] = Field(None, description="ë¬¸ì„œ ì œëª©")
    doc_type: str = Field(..., description="ë¬¸ì„œ íƒ€ì… (pdf, ppt)")
    total_pages: int = Field(..., ge=1, description="ì´ í˜ì´ì§€ ìˆ˜")
    file_path: str = Field(..., description="íŒŒì¼ ê²½ë¡œ")
    created_at: datetime = Field(default_factory=datetime.now)


class Issue(BaseModel):
    """ë°œê²¬ëœ ì´ìŠˆ"""
    issue_id: str = Field(..., description="ì´ìŠˆ ê³ ìœ  ID")
    doc_id: str = Field(..., description="ë¬¸ì„œ ID")
    page_id: str = Field(..., description="í˜ì´ì§€ ID")
    
    issue_type: IssueType = Field(..., description="ì´ìŠˆ ìœ í˜•")
    location: TextLocation = Field(..., description="í…ìŠ¤íŠ¸ ìœ„ì¹˜")
    
    original_text: str = Field(..., description="ì›ë³¸ í…ìŠ¤íŠ¸")
    message: str = Field(..., description="ì´ìŠˆ ì„¤ëª…")
    suggestion: Optional[str] = Field(None, description="ìˆ˜ì • ì œì•ˆ")
    
    confidence: float = Field(..., ge=0.0, le=1.0, description="ì‹ ë¢°ë„")
    confidence_level: ConfidenceLevel = Field(..., description="ì‹ ë¢°ë„ ë ˆë²¨")
    
    detected_at: datetime = Field(default_factory=datetime.now)
    agent_name: str = Field(..., description="ê²€ì¶œí•œ ì—ì´ì „íŠ¸ëª…")
    
    @field_validator('confidence_level', mode='before')
    def set_confidence_level(cls, v, info: ValidationInfo):
        confidence = info.data.get('confidence')
        if confidence is None:
            return v
        if confidence >= 0.9:
            return ConfidenceLevel.HIGH
        elif confidence >= 0.7:
            return ConfidenceLevel.MEDIUM
        else:
            return ConfidenceLevel.LOW


class AuditReport(BaseModel):
    """ê²€ìˆ˜ ë³´ê³ ì„œ"""
    report_id: str = Field(..., description="ë³´ê³ ì„œ ID")
    doc_id: str = Field(..., description="ëŒ€ìƒ ë¬¸ì„œ ID")
    
    issues: List[Issue] = Field(default_factory=list, description="ë°œê²¬ëœ ì´ìŠˆë“¤")
    total_issues: int = Field(default=0, ge=0, description="ì´ ì´ìŠˆ ìˆ˜")
    
    started_at: datetime = Field(default_factory=datetime.now)
    completed_at: Optional[datetime] = Field(None)
    processing_time: Optional[float] = Field(None, description="ì²˜ë¦¬ ì‹œê°„(ì´ˆ)")
    
    agents_used: List[str] = Field(default_factory=list, description="ì‚¬ìš©ëœ ì—ì´ì „íŠ¸")
    
    # ëª¨ë¸ ì „ì²´ ê²€ì¦ í›„ total_issues ìë™ ê³„ì‚°
    @model_validator(mode="after")
    def set_total_issues(self) -> "AuditReport":
        self.total_issues = len(self.issues)
        return self


# MCP ë„êµ¬ ì…ì¶œë ¥ ëª¨ë¸
class FactCheckRequest(BaseModel):
    """ì‚¬ì‹¤ í™•ì¸ ìš”ì²­"""
    sentence: str = Field(..., min_length=1, description="í™•ì¸í•  ë¬¸ì¥")
    context: Optional[str] = Field(None, description="ë¬¸ë§¥ ì •ë³´")


class FactCheckResult(BaseModel):
    """ì‚¬ì‹¤ í™•ì¸ ê²°ê³¼"""
    sentence: str = Field(..., description="í™•ì¸í•œ ë¬¸ì¥")
    is_factual: bool = Field(..., description="ì‚¬ì‹¤ ì—¬ë¶€")
    confidence: float = Field(..., ge=0.0, le=1.0, description="í™•ì‹ ë„")
    explanation: str = Field(..., description="íŒë‹¨ ê·¼ê±°")
    sources: List[str] = Field(default_factory=list, description="ì°¸ì¡° ì†ŒìŠ¤")
    checked_at: datetime = Field(default_factory=datetime.now)


class QueryRequest(BaseModel):
    """ìì—°ì–´ ì§ˆì˜ ìš”ì²­"""
    question: str = Field(..., min_length=1, description="ì‚¬ìš©ì ì§ˆë¬¸")
    doc_id: Optional[str] = Field(None, description="ëŒ€ìƒ ë¬¸ì„œ ID")


class QueryResponse(BaseModel):
    """ìì—°ì–´ ì§ˆì˜ ì‘ë‹µ"""
    question: str = Field(..., description="ì›ë³¸ ì§ˆë¬¸")
    answer: str = Field(..., description="ë‹µë³€")
    relevant_issues: List[Issue] = Field(default_factory=list, description="ê´€ë ¨ ì´ìŠˆë“¤")
    confidence: float = Field(..., ge=0.0, le=1.0, description="ë‹µë³€ ì‹ ë¢°ë„")
    generated_at: datetime = Field(default_factory=datetime.now)


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def generate_doc_id(file_path: str) -> str:
    """íŒŒì¼ ê²½ë¡œì—ì„œ ë¬¸ì„œ ID ìƒì„±"""
    import hashlib
    from pathlib import Path
    
    path = Path(file_path)
    content = f"{path.name}_{path.stat().st_mtime if path.exists() else 'unknown'}"
    return hashlib.md5(content.encode()).hexdigest()[:12]


def generate_issue_id(doc_id: str, page_id: str, location: TextLocation, issue_type: IssueType) -> str:
    """ì´ìŠˆ ID ìƒì„±"""
    import hashlib
    
    content = f"{doc_id}_{page_id}_{location.start}_{issue_type.value}"
    return hashlib.md5(content.encode()).hexdigest()[:8]


def generate_report_id(doc_id: str) -> str:
    """ë³´ê³ ì„œ ID ìƒì„±"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"report_{doc_id}_{timestamp}"


# ê²€ì¦ìš© ë”ë¯¸ ë°ì´í„° ìƒì„± í•¨ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)
def create_sample_issue(doc_id: str = "test_doc") -> Issue:
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì´ìŠˆ ìƒì„±"""
    location = TextLocation(start=10, end=20)
    return Issue(
        issue_id=generate_issue_id(doc_id, "p001", location, IssueType.TYPO),
        doc_id=doc_id,
        page_id="p001",
        issue_type=IssueType.TYPO,
        location=location,
        original_text="ì•Œê³ ë¦¬ë“¬",
        message="í‘œê¸°ë²• ì˜¤ë¥˜",
        suggestion="ì•Œê³ ë¦¬ì¦˜",
        confidence=0.95,
        confidence_level=ConfidenceLevel.HIGH,
        agent_name="quality_agent"
    )


def create_sample_report(doc_id: str = "test_doc") -> AuditReport:
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë³´ê³ ì„œ ìƒì„±"""
    sample_issue = create_sample_issue(doc_id)
    return AuditReport(
        report_id=generate_report_id(doc_id),
        doc_id=doc_id,
        issues=[sample_issue],
        agents_used=["quality_agent"]
    )


# ëª¨ë¸ ê²€ì¦ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    # ê¸°ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("ğŸ§ª ë°ì´í„° ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # 1. Issue ëª¨ë¸ í…ŒìŠ¤íŠ¸
    issue = create_sample_issue()
    print(f"âœ… Issue ìƒì„±: {issue.issue_id}")
    print(f"   ì‹ ë¢°ë„ ë ˆë²¨: {issue.confidence_level}")
    
    # 2. AuditReport ëª¨ë¸ í…ŒìŠ¤íŠ¸
    report = create_sample_report()
    print(f"âœ… Report ìƒì„±: {report.report_id}")
    print(f"   ì´ ì´ìŠˆ ìˆ˜: {report.total_issues}")
    
    # 3. JSON ì§ë ¬í™”
    report_json = report.model_dump_json(indent=2)
    print("âœ… JSON ì§ë ¬í™” ì„±ê³µ")

    # 4. ì—­ì§ë ¬í™”
    restored_report = AuditReport.model_validate_json(report_json)
    print(f"âœ… JSON ì—­ì§ë ¬í™” ì„±ê³µ: {restored_report.report_id}")
    
    print("ğŸ‰ ëª¨ë“  ëª¨ë¸ í…ŒìŠ¤íŠ¸ í†µê³¼!")